[{"title":"压测中使用openresty作为upstream来业务耗时","path":"/2023/08/14/upstream-timecost-simulate-with-openresty/","content":"最近在压测Apisix，需要按照一定的概率分布模拟请求耗时，以便达到模拟真实业务请求来压测的目的。 第一版后端程序使用Go语言，性能不达标，没法压到Apisix的极限；第二版使用Nginx作为后端程序，性能达标，压测4C8G的Apisix，极限TPS约1.4W；第三版使用openresty配合lua来模拟耗时，性能达标，4C8G的实例TPS约1.2W。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# conf.d/default.confserver &#123; listen 80; server_name _; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; access_log off; location /test &#123; content_by_lua_block &#123; ngx.say(&quot;hello world&quot;); &#125; &#125; location /sleep &#123; content_by_lua_block &#123; local resty_random = require &quot;resty.random&quot; local function random_wait_time(min_wait_time, max_wait_time) local random_bytes = resty_random.bytes(4, true) local random_float = 1 + (0xffffffff % tonumber(0xffffffff)) * 2^-32 local wait_time = min_wait_time + random_bytes:byte(1) / 0xff * (max_wait_time - min_wait_time) return wait_time end local wait_time_seed = random_wait_time(0, 10000) local wait_time = 0 if wait_time_seed &gt; 9990 then wait_time = random_wait_time(2, 5) elseif wait_time_seed &gt; 9900 then wait_time = random_wait_time(1, 2) elseif wait_time_seed &gt; 9000 then wait_time = random_wait_time(0.5, 1) elseif wait_time_seed &gt; 8000 then wait_time = random_wait_time(0.05, 0.5) else wait_time = random_wait_time(0, 0.05) end ngx.sleep(wait_time) ngx.header[&quot;Content-type&quot;] = &#x27;text/plain&#x27; ngx.say(&quot;Hello, OpenResty! I waited for &quot; .. wait_time .. &quot; seconds. Seed is &quot; .. wait_time_seed .. &quot;. &quot;) &#125; &#125; location / &#123; root /usr/local/openresty/nginx/html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/local/openresty/nginx/html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root /usr/local/openresty/nginx/html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125;&#125;","tags":["load test","openresty"]},{"title":"树莓派Airplay将有线音箱变成WiFi音箱","path":"/2023/04/15/rpi-airplay/","content":"方案选择因为是想要作为WiFi音箱使用，方案二shairport-sync更适合我 视频airplay教程：https://zhuanlan.zhihu.com/p/340535327项目地址：https://github.com/FD-/RPiPlay 音频airplay教程：https://sspai.com/post/74318项目地址：https://github.com/mikebrady/shairport-sync shairport-sync安装树莓派系统选择建议使用树莓派官方的Raspberry Pi OS，驱动全面少踩坑。之前将树莓派当做小服务器在用，一直跑的Rocky Linux，配置音箱的时候发现缺少驱动，找不到声卡。 编译安装关于如何安装参考上面的教程即可 nqptp是 Shairport Sync 监控时间的重要依赖https://github.com/mikebrady/nqptp.git sps-alsa-explore帮助配置Shairport Synchttps://github.com/mikebrady/sps-alsa-explore.git Shairport Sync本体https://github.com/mikebrady/shairport-sync 可选方案docker项目官方提供了docker方案: https://hub.docker.com/r/mikebrady/shairport-sync 12docker run -d --restart unless-stopped --net host --device /dev/snd \\ mikebrady/shairport-sync -a DenSystem -- -d hw:0 -c PCM shairport-sync配置使用sps-alsa-explore的建议配置即可 踩坑记录grep output_device查看配置选项为hw:后接字符串 1234567891011121314151617181920212223root@rpi0:~# grep output_device ./shairport-sync/audio_alsa.c -C 2 // this is very crude -- if the device is a hardware device, then it&#x27;s assumed the delay is // precise const char *output_device_name = snd_pcm_name(alsa_handle); int is_a_real_hardware_device = 0; if (output_device_name != NULL) is_a_real_hardware_device = (strstr(output_device_name, &quot;hw:&quot;) == output_device_name); // The criteria as to whether precision delay is available-- warn(&quot;The output device \\&quot;%s\\&quot; is busy and can&#x27;t be used by Shairport Sync at present.&quot;, alsa_out_dev); debug(2, &quot;the alsa output_device \\&quot;%s\\&quot; is busy.&quot;, alsa_out_dev); &#125; else if (ret == -ENOENT) &#123; die(&quot;the alsa output_device \\&quot;%s\\&quot; can not be found.&quot;, alsa_out_dev); &#125; else &#123; char errorstring[1024];-- /* Get the Output Device Name. */ if (config_lookup_string(config.cfg, &quot;alsa.output_device&quot;, &amp;str)) &#123; alsa_out_dev = (char *)str; &#125; aplay显示的设备和hw:样式对不上 123456789101112131415161718root@rpi0:~# aplay -l**** List of PLAYBACK Hardware Devices ****card 0: Headphones [bcm2835 Headphones], device 0: bcm2835 Headphones [bcm2835 Headphones] Subdevices: 8/8 Subdevice #0: subdevice #0 Subdevice #1: subdevice #1 Subdevice #2: subdevice #2 Subdevice #3: subdevice #3 Subdevice #4: subdevice #4 Subdevice #5: subdevice #5 Subdevice #6: subdevice #6 Subdevice #7: subdevice #7card 1: vc4hdmi0 [vc4-hdmi-0], device 0: MAI PCM i2s-hifi-0 [MAI PCM i2s-hifi-0] Subdevices: 1/1 Subdevice #0: subdevice #0card 2: vc4hdmi1 [vc4-hdmi-1], device 0: MAI PCM i2s-hifi-0 [MAI PCM i2s-hifi-0] Subdevices: 1/1 Subdevice #0: subdevice #0 查资料后确认，具体对应关系为hw:card名称或编号:子设备编号，而shairport-sync只需要用到card这一层，也即hw:0https://superuser.com/questions/53957/what-do-alsa-devices-like-hw0-0-mean-how-do-i-figure-out-which-to-use 关闭WiFi节能模式为了防止设备WiFi设备休眠，导致查找不到音箱，需要关闭节能模式 1iw dev wlan0 set power_save off 其他小问题修复目录权限问题journal -u shairport-sync发现有报错提示没有目录权限，不影响正常使用 12mkdir -p /home/shairport-sync/.config/pulsechown -R shairport-sync:shairport-sync /home/shairport-sync/ 最大音量调整 为了避免扰民，可以使用alsamixer设置树莓派的最大输出音量 /etc/shairport-sync.conf中有音量相关的配置，有待尝试 后续计划 使用单独usb声卡，解决自带3.5mm接口的底噪问题 重新连接后音量设置有时不会记忆的问题解决 底噪问题解决京东18块购入海贝思USB声卡，插入后免驱运行，修改配置为hw:3和Speaker，重启服务后获得了更大的音量上限和更低的底噪（还是有，小了很多） 12output_device = &quot;hw:3&quot;;mixer_control_name = &quot;Speaker&quot;;"},{"title":"etcd运维踩坑记录","path":"/2023/03/19/etcd-ops/","content":"etcd运维踩坑记录 1. 没有开启压缩导致 dbsize 一直增长etcd 的默认启动参数不会开启定期数据压缩 compact，一般程序使用 etcd 时会主动调用etcd 接口做压缩，例如 kubernetes。如果没有开启定期压缩，并且程序也没有主动调用压缩接口，那么就会有dbsize增长到上限（默认2GiB），etcd无法写入的风险。 etcd手动压缩SOP假设etcd为3节点部署，节点ip为10.0.0.1, 10.0.0.2, 10.0.0.3 确认etcd主节点，压缩操作在主节点进行 123456789101112131415# etcd 3.3及之前的版本，需要指定ETCDCTL_API变量版本export ETCDCTL_API=3etcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint status -w table# 当前主节点为10.0.0.1+------------------+------------------+---------+---------+-----------+-----------+------------+-----------------+------------------+------------+| ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX | RAFT APPLIED IDX | ERRORS | PROXY ERROR |+------------------+------------------+---------+---------+-----------+-----------+------------+-----------------+------------------+------------+| http://10.0.0.1: | d4f945f9af97d6c1 | 3.5.3 | 35 MB | true | 5 | 243336 | 243336 | | || 2379 | | | | | | | | | || http://10.0.0.2: | 7aa2e8e903c2a2d9 | 3.5.3 | 35 MB | false | 5 | 243336 | 243336 | | || 2379 | | | | | | | | | || http://10.0.0.3: | 04a31cf28c38af8e | 3.5.3 | 35 MB | false | 5 | 243336 | 243336 | | || 2379 | | | | | | | | | |+------------------+------------------+---------+---------+-----------+-----------+------------+-----------------+------------------+------------+ 在主节点上操作压缩 1234ver=$(etcdctl --endpoints=http://10.0.0.1:2379 --command-timeout=300s endpoint status --write-out=&quot;json&quot; | egrep -o &#x27;&quot;revision&quot;:[0-9]*&#x27; | egrep -o &#x27;[0-9].*&#x27;)#确认获取的reversion, 获取出来的值 -10000 ，保留前10000个历史记录echo $veretcdctl --endpoints=http://10.0.0.1:2379 --command-timeout=300s compact $(($ver-10000)) 碎片整理 1234567891011121314# 清理第一个从节点（dbsize较大时，命令执行时间比较长，请耐心等待）, 确认集群状态etcdctl --command-timeout=300s defrag --endpoints=&#x27;http://10.0.0.2:2379&#x27;etcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint status -w tableetcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint health -w table# 清理第二个从节点, 确认集群状态etcdctl --command-timeout=300s defrag --endpoints=&#x27;http://10.0.0.3:2379&#x27;etcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint status -w tableetcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint health -w table# 清理主节点, 确认集群状态etcdctl --command-timeout=300s defrag --endpoints=&#x27;http://10.0.0.1:2379&#x27;etcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint status -w tableetcdctl --endpoints=http://10.0.0.1:2379,http://10.0.0.2:2379,http://10.0.0.3:2379 endpoint health -w table 开启定期压缩注意etcd配置生效的优先级 配置文件最高优，并且如果传入了配置文件则环境变量和命令行参数都会失效 命令行参数的生效优先级高于环境变量 具体配置参考官方文档和这篇腾讯云博客 12ETCD_AUTO_COMPACTION_RETENTION=periodicETCD_AUTO_COMPACTION_RETENTION=12 2. etcd 使用鉴权访问的性能风险运维踩坑案例公司使用了apisix作为内网服务代理，apisix的路由数据是保存在etcd中的，在压测场景下，apisix会启动多个线程频繁读取etcd。如果使用了密码鉴权认证的方式，密码认证操作会成为性能瓶颈。etcd的表现为频繁的心跳超时，发生切主操作，导致集群状态不可用。针对该种情况，加大心跳超时时间到1s，选举超时到5s可以缓解。 密码鉴权密码鉴权流程可参考下图，详细可参考etcd鉴权 证书鉴权证书认证在稳定性、性能上都优于密码认证。稳定性上，它不存在 Token 过期、使用更加方便、会让你少踩坑，避免了不少 Token 失效而触发的 Bug。性能上，证书认证无需像密码认证一样调用昂贵的密码认证操作 (Authenticate 请求)，，前者更安全但是维护成本稍高需要定期替换，适合外网访问；后者使用简便适合内网，但是鉴权开销稍大， 参考资料官方文档腾讯云博客etcd压缩etcd鉴权","tags":["etcd"]},{"title":"Kindle使用笔记","path":"/2022/10/31/kindle-howto/","content":"亚马逊Kindle退出中国市场真的是噩耗，最蛋疼的是之前的书库没法用了，还是改回自己囤书，calibre的方式吧。数据掌握在自己手里最安心。 使用技巧记录漫画转换格式 部分epub漫画资源在转换成mobi之后有空白页的问题，在mobi输出转换选项中勾选忽略边距选项，mobi文件类型选择both，通过该方式转换后的mobi可在kindle上正常阅读 如果还是不行的话，也可以选择转换为pdf格式，从根源上解决页面展示问题","tags":["kindle","epub","mobi"]},{"title":"Windows10(2009)工作环境配置","path":"/2022/10/06/windows-work-env-setup/","content":"最近工作电脑换成了Windows 10，也就重新开始了我的Windows折腾之旅。回顾下当年的操作系统折腾时间线 123win98 --&gt; winxp --&gt; win vista（第一台自己的电脑） --&gt; win7 --&gt; win8 &amp; windows phone 8 --&gt; win10 &amp; win10mobile --&gt; win11 (Steam游戏机) --&gt; win10(2009版本，工作使用) --&gt; Ubuntu --&gt; Debian --&gt; Linux Mint --&gt; Deepin --&gt; Arch --&gt; LFS --&gt; Manjaro --&gt; kali --&gt; Arch / Debian / Ubuntu (个人服务器) --&gt; macOS10 --&gt; macOS11 --&gt; macOS12 (日常使用) 因为域管控的原因，工作电脑无法升级系统版本，所以以下的操作都是基于win10(2009)版本 包管理器工欲善其事必先利其器，首先得有趁手的包管理器 scoop官方网址：https://scoop.sh/ 受macOS上的homebrew启发的包管理，使用体验相近 12345# 本体安装&gt; Set-ExecutionPolicy RemoteSigned -Scope CurrentUser # Optional: Needed to run a remote script the first time&gt; irm get.scoop.sh | iex# 依赖安装scoop install git winget官方网址：https://github.com/microsoft/terminal 推荐使用scoop安装winget，然后根据实际需求选择scoop或者winget安装其他软件。Windows生态下另外一款包管理器choco和公司安装的麦咖啡冲突导致蓝屏，此处略过。 scoop install winget高版本的Windows10和Windows11自带winget，对于没有集成winget的版本，推荐使用scoop安装winget，这也是目前找到的唯一可行不升级操作系统安装winget的方式。 123456# 安装wingetscoop bucket add mainscoop install winget# 安装c++库scoop bucket add extrasscoop install vcredist Terminal 终端cmder官方网址：https://cmder.app/ 推荐使用scoop安装 12scoop bucket add mainscoop install cmder-full Windows Terminal官方网址：https://github.com/microsoft/terminal 推荐使用winget安装，方便后续更新 1winget install --id=Microsoft.WindowsTerminal -e 终端字体安装官方网址：https://github.com/tonsky/FiraCode 12scoop bucket add nerd-fontsscoop install FiraCode Visual Studio Code1winget install --id=Microsoft.VisualStudioCode -e PowerShell配置Shell工具安装(awk, grep, vim)这些工具建议使用scoop安装，scoop安装的软件大多为portable模式，方便管理 1234567891011# awkscoop bucket add mainscoop install gawk# grepscoop bucket add mainscoop install grep# vimscoop bucket add mainscoop install vim 安装新版本PowerShell1winget install Microsoft.PowerShell PowerShell profile配置PowerShell的$profile，相当于Linux的.bashrc 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152## 参考博客# https://blog.batkiz.com/posts/2020/some-pwsh-scripts/# https://blog.batkiz.com/posts/2020/some-pwsh-scripts-2/function nali &#123; param ( $Query = &#x27;&#x27;, [Alias(&#x27;l&#x27;)] $Lang = &#x27;zh&#x27; ) if ($Lang.ToLower() -eq &#x27;en&#x27; ) &#123; $Lang = &#x27;en&#x27; &#125; else &#123; $Lang = &#x27;zh-CN&#x27; &#125; $ApiUrl = &quot;http://ip-api.com/json/&#123;0&#125;?lang=&#123;1&#125;&quot; -f $Query, $Lang $info = (Invoke-WebRequest $ApiUrl).Content | ConvertFrom-Json $printInfo = &quot;&#123;0&#125;`t[&#123;1&#125; @ &#123;2&#125;, &#123;3&#125;]&quot; -f $info.query, $info.isp, $info.city, $info.country $printInfo&#125;function which &#123; $results = New-Object System.Collections.Generic.List[System.Object]; foreach ($command in $args) &#123; $path = (Get-Command $command).Source if ($path) &#123; $results.Add($path); &#125; &#125; return $results;&#125;function time &#123; $Command = &quot;$args&quot; $time = Measure-Command &#123; Invoke-Expression $Command 2&gt;&amp;1 | out-default &#125; $info = &quot;&#123;0:d2&#125;:&#123;1:d2&#125;:&#123;2:d2&#125;.&#123;3&#125;&quot; -f $time.Hours, $time.Minutes, $time.Seconds, $time.Milliseconds Write-Output $info&#125;function Get-Size &#123; param([string]$pth) &quot;&#123;0:n2&#125;&quot; -f ((Get-ChildItem -path $pth -recurse | measure-object -property length -sum).sum / 1mb) + &quot; M&quot;&#125; WSL(Windows Subsystem for Linux)WSL安装 WSL的安装可以参考之前的博文 Windows上的shell环境折腾笔记 同时附上官方教程：https://learn.microsoft.com/en-us/windows/wsl/install-manual 发行版选择图形界面kali需要图形界面推荐kali-linux，图形界面配置参考：https://www.kali.org/docs/wsl/ 1234567891011&gt; winget search kali名称 ID 版本 匹配 源----------------------------------------------------------------------Kali Linux 9PKR34TNCV07 Unknown msstoreKALITI 9WZDNCRDBPKV Unknown msstoreKalipso Profesyonel 9N4DWTDRZT9C Unknown msstoreKalipso Tüketici 9N7BL6GKFB2C Unknown msstoreKali Linux kalilinux.kalilinux 1.1.9.0 Tag: kali wingetSiriKali FrancisBanyikwa.SiriKali 1.5.0 winget&gt; winget install 9PKR34TNCV07 简洁高效Arch官方网址：https://github.com/yuk7/ArchWSL 12scoop bucket add extrasscoop install archwsl 官方默认Ubuntu123456789101112131415&gt; winget search ubuntu名称 ID 版本 匹配 源----------------------------------------------------------------------------Ubuntu 9PDXGNCFSCZV Unknown msstoreUbuntu 20.04.5 LTS 9MTTCL66CPXJ Unknown msstoreUbuntu 22.04.1 LTS 9PN20MSR04DW Unknown msstoreUbuntu 18.04.5 LTS 9PNKSF5ZN4SW Unknown msstoreUbuntu (Preview) 9P7BDVKVNXZ6 Unknown msstoreUbuntu Canonical.Ubuntu 2004.2021.825.0 wingetUbuntu 22.04 LTS Canonical.Ubuntu.2204 2204.0.10.0 Tag: ubuntu wingetUbuntu 20.04 LTS Canonical.Ubuntu.2004 2004.2021.825.0 Tag: ubuntu wingetUbuntu 18.04 LTS Canonical.Ubuntu.1804 1804.2019.522.0 Tag: ubuntu wingetUbuntu 16.04 LTS Canonical.Ubuntu.1604 1604.2019.523.0 Tag: ubuntu winget&gt; winget install Canonical.Ubuntu.2204 WSL配置管理wsl --help优先参考wsl帮助命令 easyWSL提供图形界面管理已安装发行版，同时支持将Docker镜像转化成WSL子系统 1234&gt; winget search easyWSL名称 ID 版本 源-------------------------------------easyWSL 9NHBTMKS47RB Unknown msstore 默认登录用户修改非官方版本的wsl可能没有初始化创建用户的过程，默认账户为root，可手动创建用户后，添加对应的配置实现默认用户更改 123$ cat /etc/wsl.conf[user]default=用户名 快捷键 PowerToys官方网址：https://github.com/microsoft/PowerToys 从macOS切到Windows最不习惯的是快捷键，如果说是只使用一个操作系统，那可以重新记忆习惯，然而我是macOS和Windows切换使用，就有快捷键打架的问题。 最近新发现的PowerToys的能够将常见的Windows快捷键映射成macOS快捷键，且可以一键开关映射，这样就完美解决的快捷键打架的问题，打架都用macOS的快捷键就好。 推荐使用winget安装，方便后续更新 1winget install Microsoft.PowerToys -s winget 参考键盘配置","tags":["WSL","Windows"]},{"title":"dnsmasq容器部署折腾","path":"/2022/09/20/dnsmasq-in-docker/","content":"蛋疼的华为云K8s的DNS问题最近换工作，接触各个云厂商的服务比较多，忍不住想吐槽下华为云。 华为云不支持云DNS转发，也就是说如果想要解析公司其他DNS域名的内网域名就得更换华为云的默认DNS（阿里云的Private Zone功能支持将云DNS的上游加上自建DNS，直接解决了这个问题）。如果只是用云服务器，那么换成自建DNS也不用影响，然而华为云的CCE（托管版K8s）的Node节点依赖华为云的DNS做一些劫持（主要有dockerhub劫持、华为repo内网解析、华为容器镜像仓库地址解析），将Node的/etc/resolv.conf改到了自建DNS之后，上面的劫持就失效了，也就导致Node节点没法kube-system相关镜像，也没法yum安装软件包。 所以，华为云的CCE的node节点的DNS是不能直接更换的，然而我又不得不换，因为普通网络模式的pod可以通过coredns配置将DNS请求转发到自己DNS，*但是host网络模式的pod使用的还是node上/etc/resolv.conf*。 于是，我的需求就变成了，换掉node的DNS，但是不直接换，DNS请求先走华为云的DNS，找不到记录之后再去查找自建DNS（其实就是阿里云的Private Zone功能之一） 折腾解决最终，通过在Node上部署dnsmasq，在dnsmasq中指定DNS服务器顺序，本机的DNS指向本机内网ip的方式解决了这个问题。这样相当于给K8s引入了外部依赖，不过可以通过初始化脚本解决这个问题 容器部署每个节点都需要部署的服务，使用DaemonSet部署是最方便的，配置可以使用configmap管理。既然折腾了就折腾导致，看看容器里面怎么跑dnsmasq（这其实会导致鸡生蛋蛋生鸡的问题，初始化node的时候需要先将dnsmasq的镜像放到node上才好启动服务） 踩坑一开始的启动参数是ENTRYPOINT [&quot;dnsmasq&quot;, &quot;-k&quot;]，容器启动直接退出了，没有任何报错；改为debug模式ENTRYPOINT [&quot;dnsmasq&quot;, &quot;-d&quot;]启动，服务则没有任何问题，然而线上服务不能跑在debug模式。反复尝试不同base镜像和版本，都其实失败，还没有任何日志。 最后尝试在物理机上使用dnsmasq -k正常启动，观察发现-k启动的进程运行用户是nobody，-d启动的进程用户是root，怀疑是容器中fork切换用户之后容器认为主进程退出运行了。dnsmasq --help查看帮助，发现可以指定用户。 1-u, --user=&lt;username&gt; Change to this user after startup. (defaults to nobody). 最终使用ENTRYPOINT [&quot;dnsmasq&quot;, &quot;-k&quot;, &quot;-u&quot;, &quot;root&quot;]在容器中成功启动进程 最终配置最终的可运行的容器配置如下： 123456# 使用centos镜像方便调试，最终部署可以换成alpine优化镜像大小，红帽的ubi8镜像也是不错的选择FROM centos:7RUN yum install -y dnsmasqADD ./main.conf /etc/dnsmasq.d/ADD ./dns.conf /etc/dnsmasq.d/ENTRYPOINT [&quot;dnsmasq&quot;, &quot;-k&quot;, &quot;-u&quot;, &quot;root&quot;] 123456789101112# cat ./main.confno-resolvdomain-neededno-negcachemax-cache-ttl=1enable-dbusdns-forward-max=10000cache-size=10000bind-dynamicmin-port=1024except-interface=lo# End of config 1234# cat ./dns.confserver=114.114.114.114 #自建DNSserver=100.125.1.250server=100.125.64.250 systemd部署使用systemd部署，服务启动方便，避免和容器自身形成循环依赖 12yum install -y dnsmasq 未完待续为什么dnsmasq -k在容器中会退出？","tags":["docker","dnsmasq"]},{"title":"Windows上的shell环境折腾笔记","path":"/2022/08/25/notes-on-wsl/","content":"最近工作电脑从MacOS换到了Windows 10，shell环境的缺失让我很不习惯，于是便开启我的折腾之旅。 工作电脑的Windows系统没有管理员UAC权限，没有微软应用商店，只能从内网软件中心安装软件，这也就导致操作有很多限制。 下面按照时间顺序记录下尝试过的方案 Cygwin类都是基于Cygwin的方案，使用mingw64编译器移植的Linux系工具 git for windows软件中心有git，windows版本的git是自带一个mintty的bash环境的，可以当做简单的shell环境使用。然而该方案有很大的缺点： 没有包管理器，无法安装Linux生态工具 快捷键不方便 cmderhttps://cmder.app/ 优点： 有绿色Portable版本，解压即用，不需要提权 终端界面更美观了，也可以用来调用PowerShell 缺点 没法使用ctrl+w等快捷键 没有包管理器 mobaxtermhttps://mobaxterm.mobatek.net/ 优点： 有绿色Portable版本，解压即用，不需要提权 有自己的包管理器，可以安装一些常见的软件包 兼容常见的终端快捷键 缺点： 源的使用体验一般，部分软件包的链接已失效 界面复杂，个人更喜欢简洁风格 PowerShellWindows自带的PowerShell同样很大 PowerShell5 + cmder&#x2F;Windows-TerminalShell环境不好用之后，也考虑过使用PowerShell作为替代，不过系统自带的版本不好用。其和bash的功能和使用习惯差异巨大，例如没法ctrl+r搜索历史命令，没法使用&amp;&amp;等等。 不过在折腾PowerShell期间发现了另外的神器Windows-Terminal。 https://github.com/microsoft/terminal/releases 从上面的链接下载最新版本的msixbundle安装包，双击打开安装即可拥有。或者使用PowerShell命令安装： 1Add-AppxPackage .\\app_name.appx 如果是低版本的Win10，可能需要参考以下教程去先安装VC++ v14 Desktop Framework Package https://docs.microsoft.com/troubleshoot/cpp/c-runtime-packages-desktop-bridge#how-to-install-and-update-desktop-framework-packages 上述安装操作都不需要UAC提权。 PowerShell7 + cmder&#x2F;Windows-Terminalhttps://github.com/PowerShell/PowerShell PowerShell的使用体验和bash更加接近，支持了ctrl+w, ctrl+r, &amp;&amp;等功能，且脚本可全平台运行。 安装方式双击打开或者使用下述命令都可以，同样不需要UAC提权 1Add-AppxPackage .\\app_name.appx WSL之所以一开始不选择WSL，是因为没有应用商店安装比较麻烦，且安装过程中需要申请UAC提权。 Docker Desktop上面折腾了一圈，总觉得用着不爽，所以考虑了容器方案，申请了临时管理员权限，使用了官方推荐的WSL2后端。 安装步骤如下，以下操作需要UAC提权： docker官网下载安装包并安装：https://www.docker.com/products/docker-desktop/ 按照教程加的docker-user用户组权限C:\\WINDOWS\\system32\\compmgmt.msc：https://blog.csdn.net/fragrant_no1/article/details/84256775 安装的【 Linux 内核更新包】：https://docs.microsoft.com/zh-cn/windows/wsl/install-manual#step-4---download-the-linux-kernel-update-package 重启笔记本 至此，已经拥有了完整的Linux环境。然而容器环境启动和文件操作不方便，每次重启笔记本都需要重新启动容器，Docker本身的冷启动时间较长。 Ubuntu-22.04 on WSL既然已经安装好了wsl环境，那干脆尝试安装下其他发行版吧，考虑到使用便利性，我选择了Ubuntu22.04(下载地址)下载完成后使用一下命令安装，注意，双击打开安装会报错： 1Add-AppxPackage .\\app_name.appx 此时打开Windows-Terminal发现已经添加好了Ubuntu-22.04的启动配置，新建终端标签启动即可。第一次启动需要初始化，耗时较长。 其他发行版安装可参考官方教程：https://docs.microsoft.com/en-us/windows/wsl/install-manual 至此，已经拥有了可以快速启动，无缝启动，丝般顺滑。然而WSL无法使用systemd，这就导致dockerd无法启动 Ubuntu-22.04 on WSL2于是我将目标瞄准了虚拟化更彻底的WSL2 将WSL的Linux发行版转换成WSL2很方便，只需要一条命令即可拥有，过程中不需要UAC提权： 1wsl --set-version Ubuntu-22.04 2 使用wsl-distrod方案安装systemd，具体教程见官方repo的Option 2: Make your Current Distro Run Systemd部分： https://github.com/nullpo-head/wsl-distrod 至此，我就在Windows上拥有了无缝的bash体验，使用过程中不需要UAC提权，还拥有WSL系统的root权限，完结，撒花！！！","tags":["Linux","WSL","cygwin","Shell"]},{"title":"cidr网段划分笔记","path":"/2022/08/17/cidr/","content":"哭笑不得的网段划分最近在搞服务迁移网段，将测试服务从生产网段迁移到测试网段，为了方便配置新服务器的ip，划分网段的时候计划保持最后一位不变，也即： 1210.0.0.190 --&gt; 10.0.66.19010.0.0.240 --&gt; 10.0.66.240 然而同事在帮忙创建VPC时候，从网段的最后切了两个网段10.0.66.224/28和10.0.66.240/28出去用作VPC和CEN之间的互联，这就导致我没法按照最后一段不变的方式去做ip分配了。 待迁移的ip的最后一位跨度为50，也就是我至少需要一个/26的段，于是强迫症发作的我，想当然的想要再从后往前切出一个/26的段，于是就想去网交换机上分配10.0.66.160/26这个网段，结果当然是配置校验没法通过的。反复检查了一通，在网段计算器的帮助下，我才意识到自己犯了个低级错误，网段的切分本质上是不断二分的过程，也就是不同长度的网段的开头是固定的。例如/26网段就只能是10.0.66.0/26, 10.0.66.64/26, 10.0.66.128/26, 10.0.66.192/26，真佩服自己能想出10.0.66.160/26这个网段。 最后决定新的ip地址最后一位统一减180，使用10.0.66.0/26，这样就在照顾我的强迫症的前提下，也满足了网段划分需求哈哈。 1210.0.0.190 --&gt; 10.0.66.1010.0.0.240 --&gt; 10.0.66.60 也是工作以来一直没干过网段划分的活，从来都是找别人要机器的，这次正好复习一下cidr网段划分的知识啦 后续复习CIDR定义无类别域间路由是基于可变长子网掩码（VLSM）来进行任意长度的前缀的分配的。在RFC 950（1985）中有关于可变长子网掩码的说明。CIDR包括： 指定任意长度的前缀的可变长子网掩码技术。遵从CIDR规则的地址有一个后缀说明前缀的位数，例如：192.168.0.0&#x2F;16。这使得对日益缺乏的IPv4地址的使用更加有效。 将多个连续的前缀聚合成超网，以及，在互联网中，只要有可能，就显示为一个聚合的网络，因此在总体上可以减少路由表的表项数目。聚合使得互联网的路由表不用分为多级，并通过VLSM逆转“划分子网”的过程。 根据机构的实际需要和短期预期需要而不是分类网络中所限定的过大或过小的地址块来管理IP地址的分配的过程。 需要关注的网段地址12345678910# 私有网段10/8172.16/12192.168/16# 共享地址空间，用于ISP做运营商级别NAT carrier-grade NAT (CGN)100.64.0.0/10# IBM内网9.0.0.0/8 ABCDE网段1234567891011121314151617181920212223A类地址 0. 0. 0. 0 = 00000000.00000000.00000000.00000000127.255.255.255 = 01111111.11111111.11111111.11111111 0nnnnnnn.HHHHHHHH.HHHHHHHH.HHHHHHHHB类地址128. 0. 0. 0 = 10000000.00000000.00000000.00000000191.255.255.255 = 10111111.11111111.11111111.11111111 10nnnnnn.nnnnnnnn.HHHHHHHH.HHHHHHHHC类地址192. 0. 0. 0 = 11000000.00000000.00000000.00000000223.255.255.255 = 11011111.11111111.11111111.11111111 110nnnnn.nnnnnnnn.nnnnnnnn.HHHHHHHHD类地址224. 0. 0. 0 = 11100000.00000000.00000000.00000000239.255.255.255 = 11101111.11111111.11111111.11111111 1110XXXX.XXXXXXXX.XXXXXXXX.XXXXXXXXE类地址240. 0. 0. 0 = 11110000.00000000.00000000.00000000255.255.255.255 = 11111111.11111111.11111111.11111111 1111XXXX.XXXXXXXX.XXXXXXXX.XXXXXXXX","tags":["cidr"]},{"title":"算法复杂度计算","path":"/2022/08/03/algorithm-interview/","content":"定义算法的时间复杂度使用渐进记号($\\Theta$, $O$, $\\Omega$, $o$, $\\omega$)来描述, 它们的定义如下: $$ 渐进紧确界: \\Theta (g(n))&#x3D;{f(n): 存在常量c_1, c_2和n_0, 使得对所有n&gt;&#x3D;n_0, 有0&lt;&#x3D;c_1g(n)&lt;&#x3D;f(n)&lt;&#x3D;c_2g(n)} $$$$ 渐进上界: O(g(n))&#x3D;{f(n): 存在常量c和n_0, 使得对所有n&gt;&#x3D;n_0, 有0&lt;&#x3D;cg(n)&lt;&#x3D;f(n)} $$$$ 渐进下界: \\Omega (g(n))&#x3D;{f(n): 存在常量c和n_0, 使得对所有n&gt;&#x3D;n_0, 有0&lt;&#x3D;f(n)&lt;&#x3D;cg(n)} $$$$ 非渐进紧确上界: o(g(n))&#x3D;{f(n): 对任意常量c&gt;0, 存在常量n_0&gt;0, 使得对所有n&gt;&#x3D;n_0, 有0&lt;&#x3D;f(n)&lt;cg(n)} $$$$ 非渐进紧确下界: \\omega(g(n))&#x3D;{f(n): 对任意常量c&gt;0, 存在常量n_0&gt;0, 使得对所有n&gt;&#x3D;n_0, 有0&lt;&#x3D;cg(n)&lt;f(n)}$$ 这些渐进记号中平常常用的是前三种($\\Theta$, $O$, $\\Omega$), 因为日常使用中我们最关心最坏情况下时间复杂度, 所以渐进上界$O$也是最为常用的记号. 对于这三种记号, 结合算法导论上的配图很好理解. $O$描述了最坏情况下的时间复杂度量级; $\\Omega$描述了最好情况下的时间复杂度量级; $\\Theta$是由$O$和$\\Omega$组成的一个区间; 将渐进记号和实数之间的大小比较作类比, 也更好理解:$$ f(n) &#x3D; O(n) 类似于 a &lt;&#x3D; b $$$$ f(n) &#x3D; \\Omega (n) 类似于 a &gt;&#x3D; b $$$$ f(n) &#x3D; \\Theta (n) 类似于 a &#x3D; b $$$$ f(n) &#x3D; o(n) 类似于 a &lt; b $$$$ f(n) &#x3D; \\omega (n) 类似于 a &gt; b $$ 运算渐进函数具有传递性, 自反性, 对称性和转置对称性. 举例来说:$$ 传递性: f(n) &#x3D; O(g(n)) 且 g(n) &#x3D; O(h(n)) &#x2F;Rightarrow f(n)&#x3D;O(h(n)) $$$$ 自反性: f(n)&#x3D;O(f(n)) $$$$ 转置对称性: f(n) &#x3D; O(g(n)) 当且仅当 g(n) &#x3D; \\Omega (f(n)) $$ 利用这些性质可以通过推导的方式得出算法的时间复杂度. 以快速排序为例 12345678# 提供一个最好理解的递归实现def quiksort(l): if len(l) &lt; 2: return l anchor = l[0] left = [i for i in l[1:] if i &lt; anchor] #注意l[1:] right = [i for i in l[1:] if i &gt;= anchor] return quiksort(left) + [anchor] + quiksort(right) 时间复杂度推导公式如下:$$\\begin{equation}\\begin{split}T(n) &amp;&#x3D; O(n) + 2 * T(n&#x2F;2) \\&amp;&#x3D; O(n) + 2 * O(n&#x2F;2) + 4 * T(n&#x2F;4) \\&amp;&#x3D; \\sum_{i&#x3D;1}^{lg(n)} O(n) \\&amp;&#x3D; O(nlg(n))\\end{split}\\end{equation}$$ 附上不同算法复杂度的增长趋势:https://www.geogebra.org/calculator/brd6wjte","tags":["面试","algorithm","排序"]},{"title":"overlay2笔记","path":"/2022/08/03/what-is-overlay2/","content":"overlay2文件系统的原理overlay2的实现原理直观如下图： 可以使用下面的命令做简单的模拟： 123mkdir -p /overlaytest/client_1/&#123;upperdir,workdir&#125; /overlaytest/client_2/&#123;upperdir,workdir&#125; lowerdir merged/&#123;client_1,client_2&#125;mount -t overlay overlay -o lowerdir=/overlaytest/lowerdir -o upperdir=/overlaytest/client_1/upperdir -o workdir=/overlaytest/client_1/workdir /overlaytest/merged/client_1mount -t overlay overlay -o lowerdir=/overlaytest/lowerdir -o upperdir=/overlaytest/client_2/upperdir -o workdir=/overlaytest/client_2/workdir /overlaytest/merged/client_2 对比docker的文件驱动的发展路径是：aufs --&gt; devicemapper --&gt; overlay --&gt; overlay2，目前生产中用的最多的是devicemapper和overlay2。 devicemapperdevicemapper使用lvm作为底层实现技术，有thin pool空间满和inode占用高的问题。 squashfs只读文件系统，软路由系统openwrt推荐的文件系统格式。系统文件本身只读，变动通过overlay文件系统挂载，这样就实现了系统重置的功能。 mount --bindmount --bind可以实现类似于overlay2的功能，可以替换掉目录下的某一个文件或者文件夹 其他值得关注的点inode性能问题哪些drive有inode问题？devicemapper&#x2F;overlay有inode问题，overlay中使用硬链接可能导致inode问题，overlay2的inode利用率更高，规避了该问题 f_type如果使用xfs文件系统，需要主要f_type选项设置为1，否则无法使用overlay2。具体可通过xfs_info查看 pagecacheoverlay2文件系统是共享pagecache的，这样对于底层文件系统中同一个文件的读取可以通过共用pagecache来提高效率，不过这也意味着容器化不能完全隔离pagecache copy on writecopy on write特性，导致如果先读取lowerdir的文件，会感知不到后续修改。该问题使用python脚本未复现，生产环境中通过挂载日志目录。 renamerename(2) systemcall的支持有差别，具体件参考文档 参考文档https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txthttps://docs.docker.com/storage/storagedriver/overlayfs-driver/https://gdevillele.github.io/engine/userguide/storagedriver/overlayfs-driver/https://gdevillele.github.io/engine/userguide/storagedriver/device-mapper-driver/https://blog.k8s.li/Exploring-container-image.htmlhttps://mp.weixin.qq.com/s/yacj95ltAZ3NfM-lv2NyXQhttps://blogs.cisco.com/developer/373-containerimages-03","tags":["docker","overlay2","devicemapper","union filesystem"]},{"title":"理解用户空间与内核空间","path":"/2022/06/21/user-space-kernel-space/","content":"最近面试被问到了用户空间和内核空间的问题，发现脑子以为懂了和嘴巴说出来之间有一段距离，就用写作来填平吧。 什么是用户空间和内核空间？在Linux中，系统内存可以分为用户空间(user space)和内核空间(kernel space)，用户空间是运行用户进程的内存空间，内核空间是运行内核进程的内存空间。 为什么要区分用户空间和内核空间系统内核位于用户进程和硬件资源之间，将硬件资源虚拟化，提供了接口，可以让用户进程访问硬件资源，并且负责管理硬件资源的调度。具体来说，内核主要干这四件事情： 内存管理：跟踪所有进程用了哪些内存、用了多少、存在了哪个物理地址等等 进程管理：管理进程对CPU时间分片的占用 设备驱动：作为中间人或者解释器，替进程访问硬件设备（Unix系统中一切皆文件的思想，就是对硬件设备的绝妙抽象） 系统调用system calls与安全：接收从用户空间传来的系统调用，做安全检查并执行（什么是系统调用后面细说） 以上可以看出为什么要区分用户空间和内核空间，一方面这样的分层设计可以让系统内核的维护更加灵活，另一方面可以让系统更加安全，敏感的操作通过统一的syscalls接口切换到内核空间中完成。 Linux中的系统调用流程如下图，syscalls是通过汇编语言指令的方式提供的，我们最经常接触的进程实际上是调用的glibc/解释器/编译器等库提供的功能，这也是为什么Linux发行版中单独升级glibc版本是一个风险很大的操作（glibc的版本变更可能导致很多系统基础组件的syscalls不兼容） system calls系统调用如此重要，那么它具体提供了哪些功能呢？syscalls的详细内容可以参考man syscalls，主要包含进程控制(fork,exit,wait)、文件管理(open,read,write,close)、设备管理(ioctl,read,write)、进程信息维护(getpid,alarm,sleep)、进程间通信(pipe,shmget,mmap)等等。 下面简单介绍下常见的syscall的作用：open()：打开文件，返回文件描述符，详细可参考链接 read()：读取文件，读取的文件需要有文件描述符标识，读取前需要先执行open()，read()系统调用需要传入三个参数（文件描述符fd、文件读缓存的地址、读取的字节数）；这里涉及到了读写缓存的概念，这个缓存是由内核维护在内存中的page cache，具体可参考链接 write()：写入文件，这是程序输入的常见方式之一，write()系统调用需要传入三个参数（文件描述符、写缓存的地址、写入的字节数） close()：关闭文件，释放文件描述符 fork()：创建子进程，详细参考链接 wait()：等待子进程结束，返回子进程的返回值。如果子进程执行结束了，父进程没有执行wait，就会产生僵尸进程。运维层面解决僵尸进程的方法是kill父进程，让僵尸进程成为孤儿进程，又init进程来执行wait，让僵尸进程死亡。程序代码实现层面有两种方式避免僵尸进程，1)调用wait(), 2) fork()两次让init进程来管理子进程。需要注意的是，kill父进程和fork()两次在容器里面不管用，因为容器里面通常没有init进程存在，这种情况需要重启容器来解决。对于僵尸进程的详细讲解可以参考链接 exit()：退出进程，返回值为0，在多线程场景中则表示该线程执行结束。操作系统会回收exit()进程的资源 kill()：可以参考常用的kill命令理解，发送不同信号量例如SIGINT、SIGKILL等等。 中断pass 用户空间和内核空间在Linux、Windows和MacOS中的区别？上面关于用户空间和内核空间的讨论都是基于Linux的，这些功能在Windows和macOS上的实现是又差别的，具体又涉及到了宏内核和微内核设计的差异，我的知识还不足以讲清楚这些。但不管那种实现都提供了类似的用户空间和内核空间的抽象。下面仅提供文章和图片用于参考~ 关于微内核的对话聊了聊宏内核和微内核，并吹了一波 Linux 参考资料 https://www.redhat.com/en/topics/linux/what-is-the-linux-kernel https://www.redhat.com/en/blog/architecting-containers-part-1-why-understanding-user-space-vs-kernel-space-matters https://www.redhat.com/en/blog/architecting-containers-part-2-why-user-space-matters https://www.redhat.com/en/blog/architecting-containers-part-3-how-user-space-affects-your-application 内核空间定义 用户空间定义 https://www.tutorialspoint.com/what-is-the-purpose-of-system-calls# 孤儿进程与僵尸进程 聊了聊宏内核和微内核，并吹了一波 Linux","tags":["linux","user-space","kernel-space","八股文"]},{"title":"卸载无影云桌面以及相关插件","path":"/2022/05/18/uninstall-wuying/","content":"最近阿里云的无影云桌面在做免费推广，出于好奇试用了下。分别尝试了mac桌面端和网页版，发现网页版已经满足使用需求了。于是决定卸载桌面端。 round 1在访达finder的应用程序文件夹中找到对应的app执行删除 然而今天重启笔记本之后发现有个Elastic Desktop Service还是会开机自启 round 2猜测和第一次启动的时候安装的插件有关，但是程序弹窗要求提权 查看任务管理器和程序关于，基本确认是Citrix插件没有卸载干净 怀疑Library下面有部分文件没有删除，删除之 round 3然而重启之后Elastic Desktop Service还是出现了！！！ 重新查文档，发现无影云桌面可能是使用的这家公司的服务，Citrix官网是提供了卸载程序的 最后别忘了将Library下面的文件再删一遍 end折腾就像生活，不放弃多学习多尝试，总能有所收获","tags":["macOS","日常折腾"]},{"title":"计算机网络学习笔记","path":"/2022/05/16/learning-network/","content":"最近复习计算机网络相关的知识，发现了一个很适合用来入门计算机网络的博客《小菜学网络》。一口气读完，有种酣畅淋漓的感觉，作者的讲解让我将脑海中计算机网络基础知识串了起来。 我的笔记 URLhttps://fasionchan.com/network/http/url/ 7层网络模型和协议","tags":["计算机网络","面试"]},{"title":"使用hexo将博客迁移到GitHub Pages","path":"/2022/05/09/migrate-my-blog-to-github-pages-with-hexo/","content":"博客搭建和迁移hexo的官网文档很详细，这里主要记载使用hexo+Github Pages过程中遇到的坑 GitHub项目创建可参考《超详细Hexo+Github博客搭建小白教程》 如果是按照步骤1新建的项目，_config.yml中的url只需要填写网址即可，不用加上project12345678# URL## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;url: https://changediff.github.iopermalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing &#x27;index.html&#x27; from permalinks trailing_html: true # Set to false to remove trailing &#x27;.html&#x27; from permalinks 搭好之后就可以开始迁移了，不过我不打算将之前的文章搬过来了。知识常学常新嘛，这里就记录2022年3月之后的学习感悟吧。 博客主题选择推荐两个主题one-paper和stellar，功能界面不华丽，但是很适合用来专注写作 one-paperone-paper是一个很干净纯粹的阅读主题，界面很有设计感，不过目前功能很少，可以关注一波作者的更新。 具体使用方法参考官方链接即可，默认的配置只有文章和关于。 1234menu: 首页: / 归档: /archives 关于: /about stellarstellar是一个内置 wiki 系统的 hexo 主题，拥有简约而精美的视觉设计和丰富又灵活的标签插件。 使用技巧插入图片 安装markdown插件 1npm install hexo-renderer-marked --save .config.yml中打开图片路径配置 1234post_asset_folder: truemarked: prependRoot: true postAsset: true 插入图片的时候注意语法，只填写图片文件名，图片放在和md同级的资源目录中 12# migrate-my-blog-to-github-pages-with-hexo/test-img.png![我是一张图片](flow_chart.png) 后遗症：本地无法正常渲染预览markdown end至此，虽然有点小瑕疵，我的博客发布流程全部迁移到了GitHub pages上面，可以愉快地使用vscode+git来写博客啦~","tags":["hexo","GitHub Pages"]},{"title":"iptables入门笔记","path":"/2022/05/06/iptables-howto/","content":"iptables是基于Linux内核模块Netfilter的防火墙工具，可以按照一定的规则对ip packet执行监控、修改、转发、重定向、丢弃等操作；ipv6版本的是ip6talbles；nftables则是iptables的新实现。目前，iptables还是使用最广泛的Linux防火墙模块，本文也聚焦于iptables的入门使用。 关键概念iptables的操作对象是ip包。Tables --&gt; Chains --&gt; Rules --&gt; IP Packets，可以按照这样的层级来理解iptables的组织逻辑 IP packet IP包对于ip包的详细讲解可以参考这篇博客 部分iptables的功能需要修改ip包的内容，例如通过修改ip包的源地址实现、目的地址实现SNAT、DNAT、包FORWARD等等功能。 Tables 表iptables共有5张表，分别是： raw表，只用于一种场景：修改ip包以逃过连接跟踪； filter表，顾名思义——过滤，是默认表，大多数防火墙功能都和filter表有关； nat表，用作网络地址转换，例如端口转发功能（后面会讲到）； mangle表，用于修改特殊包； security表，MAC相关的规则，典型的应用是SELinux 大多数情况下，我们只会用到filter和nat表，本文也围绕这两个表展开 Chains 链表是由链(Chain)组成的，有5个默认链，用户也可以自定义链，例如Docker就是使用了iptables自定义链来实现了网络隔离。默认链有默认的策略ACCEPT，可以修改成DROP；每条链上会有n个规则，规则可以定义自己的策略。 链的名称都比较清晰明了，可顾名思义，具体如下： PREROUTING，ip包被路由前(进来或发送前)相关操作，例如DNAT INPUT，入包相关操作 FORWARD，包转发相关操作 OUTPUT，出包相关操作 POSTROUTING，路由后修改包相关操作，例如SNAT 自定义链 上面的iptables流程图可能比较难以理解，它实际上是将入包、出包、转发的流程画到了一张图里面，如果将这三个流程分别标记出来就能够比较清晰地知道在入包、出包、转发过程中iptables做了哪些操作 Rules 规则常见用途1. 网络防火墙123456# 封禁dockerd默认端口2375的外部访问iptables -A INPUT -p tcp --dport 2375 -j REJECT# 允许192.168.64.2访问本机2375端口iptables -I INPUT -p tcp --dport 2375 -s 192.168.64.2 -j ACCEPT 2. docker-proxy网络代理运行nginx测试容器，并添加端口映射。看出容器之间的通信走docker0网桥，端口映射则是通过docker-proxy转发 123456789101112root@ubuntu2204:/home/ubuntu# docker run -dit --name nginx -p 8080:80 nginxroot@ubuntu2204:/home/ubuntu# ip routedefault via 192.168.64.1 dev enp0s1 proto dhcp src 192.168.64.5 metric 100172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1192.168.64.0/24 dev enp0s1 proto kernel scope link src 192.168.64.5 metric 100192.168.64.1 dev enp0s1 proto dhcp scope link src 192.168.64.5 metric 100root@ubuntu2204:/home/ubuntu# lsof -i:8080COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEdocker-pr 1488 root 4u IPv4 20593 0t0 TCP *:http-alt (LISTEN)docker-pr 1493 root 4u IPv6 20599 0t0 TCP *:http-alt (LISTEN) 具体的转发是通过iptables规则实现的 123456789101112131415161718192021222324252627282930313233343536373839root@ubuntu2204:/home/ubuntu# iptables-save# Generated by iptables-save v1.8.7 on Fri May 6 00:18:54 2022*filter:INPUT ACCEPT [0:0]:FORWARD DROP [0:0]:OUTPUT ACCEPT [0:0]:DOCKER - [0:0]:DOCKER-ISOLATION-STAGE-1 - [0:0]:DOCKER-ISOLATION-STAGE-2 - [0:0]:DOCKER-USER - [0:0]-A FORWARD -j DOCKER-USER-A FORWARD -j DOCKER-ISOLATION-STAGE-1-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -o docker0 -j DOCKER-A FORWARD -i docker0 ! -o docker0 -j ACCEPT-A FORWARD -i docker0 -o docker0 -j ACCEPT-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 80 -j ACCEPT-A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2-A DOCKER-ISOLATION-STAGE-1 -j RETURN-A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP-A DOCKER-ISOLATION-STAGE-2 -j RETURN-A DOCKER-USER -j RETURNCOMMIT# Completed on Fri May 6 00:18:54 2022# Generated by iptables-save v1.8.7 on Fri May 6 00:18:54 2022*nat:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]:DOCKER - [0:0]-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER-A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 80 -j MASQUERADE-A DOCKER -i docker0 -j RETURN-A DOCKER ! -i docker0 -p tcp -m tcp --dport 8080 -j DNAT --to-destination 172.17.0.2:80COMMIT# Completed on Fri May 6 00:18:54 2022 123456789101112131415161718192021222324252627282930313233root@ubuntu2204:/home/ubuntu# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destinationChain FORWARD (policy DROP 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER-USER all -- * * 0.0.0.0/0 0.0.0.0/0 0 0 DOCKER-ISOLATION-STAGE-1 all -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- * docker0 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED 0 0 DOCKER all -- * docker0 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- docker0 !docker0 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- docker0 docker0 0.0.0.0/0 0.0.0.0/0Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destinationChain DOCKER (1 references) pkts bytes target prot opt in out source destination 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.2 tcp dpt:80Chain DOCKER-ISOLATION-STAGE-1 (1 references) pkts bytes target prot opt in out source destination 0 0 DOCKER-ISOLATION-STAGE-2 all -- docker0 !docker0 0.0.0.0/0 0.0.0.0/0 0 0 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0Chain DOCKER-ISOLATION-STAGE-2 (1 references) pkts bytes target prot opt in out source destination 0 0 DROP all -- * docker0 0.0.0.0/0 0.0.0.0/0 0 0 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0Chain DOCKER-USER (1 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0 3. cni To Be Continued 参考文献 iptables - ArchWiKi iptables(8) - Arch manual pages 小菜学网络 nftables - ArchWiKi Iptables Tutorial 1.2.2 Docker and iptables","tags":["Linux","iptables"]},{"title":"CentOS7升级systemd版本到416.1","path":"/2022/04/17/rpm-backports/","content":"本文主要记录下在CentOS7折腾升级systemd的过程中踩得坑，方便以后需要的时候能够快速复盘。CentOS7中默认开启cgorupv2需要升级systemd版本，当前最靠谱的升级方式为Facebook维护的backports 具体打包过程中见GitHub 0. 搭建本地仓库打包好的rpm包在repo目录下，可以使用createrepo命令快速搭建自定义mirror 123456789101112# 创建repodatecreaterepo repo/cd repo# 启动http服务提供本地rpm源服务nohup python -m SimpleHTTPServer &amp;cat &lt;&lt; EOF | tee /etc/yum.repos.d/localhost[localhost]name=localhostbaseurl=http://127.0.0.1:8000/enabled=1gpgcheck=0EOF 在此基础上，新增配置epel repo和elrepo 完成源配置之后，参考步骤1到3可在CentOS7.9系统上复现打包过程 1. 安装并配置mock工具包安装1yum install fedora-packager 自定义源配置自定义源配置如下，&#x3D;&#x3D;注意先启动本地rpm源服务&#x3D;&#x3D; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253cd /etc/mock# 查看默认配置mock]# cat default.cfginclude(&#x27;templates/epel-7.tpl&#x27;)config_opts[&#x27;root&#x27;] = &#x27;epel-7-x86_64&#x27;config_opts[&#x27;target_arch&#x27;] = &#x27;x86_64&#x27;config_opts[&#x27;legal_host_arches&#x27;] = (&#x27;x86_64&#x27;,)# 添加自定义源cp templates/epel-7.tpl templates/epel-7.tpl.bakcat &lt;&lt; EOF | tee templates/epel-7.tplinclude(&#x27;templates/centos-7.tpl&#x27;)config_opts[&#x27;chroot_setup_cmd&#x27;] = &#x27;install @buildsys-build&#x27;config_opts[&#x27;yum.conf&#x27;] += &quot;&quot;&quot;[localhost]name=localhostbaseurl=http://127.0.0.1:8000/enabled=1gpgcheck=0[epel]name=Extra Packages for Enterprise Linux \\$releasever - \\$basearchmirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=epel-7&amp;arch=\\$basearchfailovermethod=prioritygpgkey=file:///usr/share/distribution-gpg-keys/epel/RPM-GPG-KEY-EPEL-7gpgcheck=1skip_if_unavailable=False[epel-testing]name=Extra Packages for Enterprise Linux \\$releasever - Testing - \\$basearchenabled=0mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=testing-epel7&amp;arch=\\$basearchfailovermethod=priorityskip_if_unavailable=False[local]name=localbaseurl=https://kojipkgs.fedoraproject.org/repos/epel7-build/latest/\\$basearch/cost=2000enabled=0skip_if_unavailable=False[epel-debuginfo]name=Extra Packages for Enterprise Linux \\$releasever - \\$basearch - Debugmirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=epel-debug-7&amp;arch=\\$basearchfailovermethod=priorityenabled=0skip_if_unavailable=False&quot;&quot;&quot;EOF 2. 制作dependencies的rpm包123cd dependenciesmock --rebuild curl-7.49.0-1.fc25.src.rpmcp /var/lib/mock/epel-7-x86_64/result/*.rpm repo 3. 制作backport rpm包部分包的编译顺序有依赖12345util-linux --&gt; systemd-compat-libsrpm-4.13.1 --&gt; systemd# 已不用编译python34的依赖，修改spec文件改用python36# python34-cssselect --&gt; python34-lxml --&gt; systemd --&gt; dbus-broker 编译命令123456# 下载源代码spectool -g -R rpms/systemd/specfiles/systemd.spec# 打包src.rpmrpmbuild -bs rpms/systemd/specfiles/systemd.spec# 使用src.rpm打包二进制rpmmock --rebuild /root/rpmbuild/SRPMS/systemd-246.1-1.fb7.src.rpm 4. 其他说明4.1 包维护说明 项目 说明 fedora历史版本src.rpm下载 https://koji.fedoraproject.org/koji/index centos历史版本src.rpm下载 https://cbs.centos.org/koji/index spec规范文档 https://docs.fedoraproject.org/en-US/packaging-guidelines/ 4.2 systemd安装注意点 想要默认启动systemd，需要确保initrd启动调用的systemd为打包后的版本，通过dmesg可以查看。具体参考issue 升级systemd，注意要先升级systemd再升级内核，不然需要在重启后用dracut工具重新生成initrd","tags":["Linux","CentOS","rpm"]},{"title":"从外接USB设备启动树莓派4b","path":"/2021/02/28/rpi4b-usb-boot/","content":"树莓派默认从tf卡启动系统，io性能太弱了。最近入手了Argon ONE外壳，可以通过usb外接一个m.2 sata接口的固态硬盘；那么，折腾一下从ssd吧。 方案调查一番查资料，目前支持两种启动方案： 升级固件，这也是网上推荐的主流方案。这个方案需要先用原版的raspbian升级固件，这样就可以直接设置从USB设备引导。找到的靠谱教程如下：1. New Raspberry Pi 4 Bootloader USB &#x2F; Network Boot Guide2. Raspberry Pi 4 Ubuntu USB Boot (No SD Card) 然鹅，我现在用的是Ubuntu系统，这个方案折腾起来比较麻烦，可能还需要重装系统。pass 从tf卡引导，将根目录替换成ssd的分区。这样理论上兼容性更好，而且可以在现有的系统上升级。不犹豫，马上开搞。参考教程：Raspberry Pi 4 USB Boot Config Guide for SSD &#x2F; Flash Drives 方案实施 复制现有系统到ssd，&#x3D;&#x3D;注意，这个操作会清空SSD上面的数据&#x3D;&#x3D; 1dd bs=4M if=/dev/mmcblk0 of=/dev/sda 确认usb设备id，我的是174c:55aa 123lsusbBus 002 Device 003: ID 174c:55aa ASMedia Technology Inc. Name: ASM1051E SATA 6Gb 修改cmdline.txt，树莓派是通过这个文件来确认系统启动目录的，直接修改fstab无效 12345678# 备份cp cmdline.txt cmdline.txt.bak# 修改为如下内容：## 1. 注意将XXXX:XXXX替换为上一步获取的usb id## 2. 注意root=的配置，需要和硬盘对应的LABEL或者UUID一致（如果是dd复制的数据，这块应该不用改）usb-storage.quirks=XXXX:XXXX:u net.ifnames=0 dwc_otg.lpm_enable=0 console=serial0,115200 console=tty1 root=LABEL=writable rootfstype=ext4 elevator=deadlinerootwait fixrtc 更新/etc/fstab，这一步其实不是必须的，为了不造成迷惑，还是和cmdline.txt的配置保持一致了。 reboot之后就可以看到/目录已经切换到ssd上面了 12ubuntu@rpi:~$ findmnt -n -o SOURCE //dev/sdb2 不服跑个分，io速度提升10倍，哈哈： 1234567891011121314sudo curl https://raw.githubusercontent.com/TheRemote/PiBenchmarks/master/Storage.sh | sudo bash Category Test ResultHDParm Disk Read 185.42 MB/sHDParm Cached Disk Read 185.55 MB/sDD Disk Write 92.6 MB/sFIO 4k random read 4429 IOPS (17716 KB/s)FIO 4k random write 5109 IOPS (20439 KB/s)IOZone 4k read 21790 KB/sIOZone 4k write 19337 KB/sIOZone 4k random read 16226 KB/sIOZone 4k random write 20809 KB/s Score: 4777","tags":["rpi","Linux"]},{"title":"利用kube-state-metrics自动生成prometheus的配置文件","path":"/2021/02/09/use-kube-sate-metrics-for-service-discovery/","content":"最近运维的k8s集群的node节点变动频繁，总是要手动更新prometheus配置文件表示很蛋疼。所以研究一下怎么对node节点做service discovery，自动更新监控targets列表。 先看看已有的配置维护方案prometheus的配置通过file_sd_config实现动态加载，用Python脚本访问每个集群的apiserver获取node节点然后生成对应的json配置文件。 这个方案可以拿来直接用的，不过配置起来不够灵活。我不想在脚本里面维护各个集群的认证方式，只想安安静静的更新prometheus自己的配置。pass 再看看prometheus官方提供的方案prometheus提供了kubernetes_sd_config，可以在prometheus.yml中配置好集群的认证方式，这样prometheus会定期去各个apiserver获取需要监控的node列表。在测试环境折腾了半天，发现这种方式对于部署在内部的prometheus配置起来很友好，然后如果是多个集群共用一个prometheus的话认证证书维护起来比较麻烦且容易出现集群认证配置更新了，prometheus中的配置没更新的尴尬情况。虽说集群的认证更新不会很频繁，但是每次更新就得重启prometheus也是不方便。 所以这种的确是最优雅的方案，也被pass了。 我的方案最后在研究promethes的各个监控项目的时候，发现了kubernetes官方提供了详细的node节点监控：kube-state-metrics，这些监控配置同样可以通过file_sd_config动态加载。于是有了以下方案： 人工维护kube-state-metrics的配置groups/kube-state-metrics/*.json，使用定时执行的脚本通过获取localhost的prometheus监控数据来更新node列表 prometheus部署 prometheus.yaml中必备配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# my global configglobal: scrape_interval: 60s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. scrape_timeout: 60s # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: &#x27;k8s-prometheus-monitor&#x27;alerting: alertmanagers: - static_configs: - targets: [&quot;localhost:9093&quot;]# Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.rule_files: # - &quot;first.rules&quot; # - &quot;second.rules&quot; - /home/server/prometheus/rule.yml# A scrape configuration containing exactly one endpoint to scrape:# Here it&#x27;s Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: &#x27;prometheus&#x27; # metrics_path defaults to &#x27;/metrics&#x27; # scheme defaults to &#x27;http&#x27;. static_configs: - targets: [&#x27;localhost:9090&#x27;] - job_name: &#x27;kube-state-metrics&#x27; scrape_interval: 180s scrape_timeout: 30s file_sd_configs: - files: [&#x27;groups/kube-state-metrics/*.json&#x27;] metric_relabel_configs: - source_labels: [__name__] regex: &quot;(kube_node_status_condition|kube_node_labels|kube_node_info|kube_pod_container_resource_requests_cpu_cores|kube_node_status_allocatable_cpu_cores|kube_pod_container_resource_requests_memory_bytes|kube_node_status_allocatable_memory_bytes)&quot; action: keep - job_name: &#x27;cadvisor&#x27; scrape_interval: 90s scrape_timeout: 30s file_sd_configs: - files: [&#x27;groups/cadvisor/*.json&#x27;] metric_relabel_configs: - source_labels: [__name__] regex: &quot;(container_cpu_usage_seconds_total|container_memory_rss|container_memory_usage_bytes|container_spec_memory_limit_bytes|container_spec_cpu_quota|container_memory_swap|container_memory_cache|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_cpu_user_seconds_total|container_cpu_system_seconds_total|container_memory_failures_total|container_fs_reads_bytes_total|container_fs_writes_bytes_total|container_cpu_cfs_throttled_seconds_total|container_memory_working_set_bytes|kube_deployment_spec_replicas|kube_node_status_capacity_cpu_cores|kube_pod_container_resource_limits|kube_pod_container_resource_limits_cpu_cores|kube_pod_container_resource_limits_memory_bytes|kube_pod_container_resource_requests|kube_pod_container_resource_requests_cpu_cores|kube_replicationcontroller_spec_replicas|kube_replicationcontroller_status_replicas)&quot; action: keep # kubernetes &gt; 1.13 - job_name: &#x27;cadvisor-standalone&#x27; scrape_interval: 90s scrape_timeout: 30s file_sd_configs: - files: [&#x27;groups/cadvisor-standalone/*.json&#x27;] metric_relabel_configs: - source_labels: [&#x27;container_label_io_kubernetes_pod_name&#x27;] target_label: &#x27;pod_name&#x27; - source_labels: [&#x27;container_label_io_kubernetes_container_name&#x27;] target_label: &#x27;container_name&#x27; - source_labels: [__name__] regex: &quot;(container_cpu_usage_seconds_total|container_memory_rss|container_memory_usage_bytes|container_spec_memory_limit_bytes|container_spec_cpu_quota|container_memory_swap|container_memory_cache|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_cpu_user_seconds_total|container_cpu_system_seconds_total|container_memory_failures_total|container_fs_reads_bytes_total|container_fs_writes_bytes_total|container_cpu_cfs_throttled_seconds_total|container_memory_working_set_bytes|kube_deployment_spec_replicas|kube_node_status_capacity_cpu_cores|kube_pod_container_resource_limits|kube_pod_container_resource_limits_cpu_cores|kube_pod_container_resource_limits_memory_bytes|kube_pod_container_resource_requests|kube_pod_container_resource_requests_cpu_cores|kube_replicationcontroller_spec_replicas|kube_replicationcontroller_status_replicas)&quot; action: keep - job_name: &#x27;node-exporter&#x27; scrape_interval: 90s scrape_timeout: 30s file_sd_configs: - files: [&#x27;groups/node-exporter/*.json&#x27;] metric_relabel_configs: - source_labels: [__name__] regex: &quot;(node_cpu_seconds_total|node_memory_MemAvailable_bytes|node_memory_MemTotal_bytes|node_load1|node_load5)&quot; action: keep docker-comose.yaml配置 123456789101112131415161718192021222324252627282930313233prometheus: image: prom/prometheus:v2.24.1 net: host restart: always environment: - TZ=Asia/Shanghai volumes: - /etc/localtime:/etc/localtime:ro - ./prometheus/:/etc/prometheus/ - /home/data/prometheus_data/:/prometheus_data/:rw command: - &#x27;--config.file=/etc/prometheus/prometheus.yml&#x27; - &#x27;--storage.tsdb.path=/prometheus_data/&#x27; - &#x27;--storage.tsdb.retention.time=2d&#x27; - &#x27;--storage.tsdb.max-block-duration=2h&#x27; - &#x27;--storage.tsdb.min-block-duration=2h&#x27; - &#x27;--query.max-samples=100000000&#x27; - &#x27;--web.console.libraries=/usr/share/prometheus/console_libraries&#x27; - &#x27;--web.console.templates=/usr/share/prometheus/consoles&#x27; ports: - 9090:9090alertmanager: image: prom/alertmanager ports: - 9093:9093 volumes: - ./alertmanager/:/etc/alertmanager/ net: host restart: always command: - &#x27;--config.file=/etc/alertmanager/config.yml&#x27; - &#x27;--storage.path=/alertmanager&#x27; 启动脚本 12345#!/bin/bashmkdir -p /home/server/prometheus/groups/&#123;kube-state-metrics,node-exporter,cadvisor,cadvisor-standalone&#125;mkdir -p /home/data/prometheus_data/mkdir -p /home/server/alertmanager/ Python脚本生成node配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120# coding: utf-8import jsonimport socketimport timefrom datetime import datetimeimport requestsdef send_alarm(msg): passdef simple_query(query=&#x27;kube_node_status_condition&#123;status=&quot;true&quot;&#125;==1&#x27;): &quot;&quot;&quot; 获取5分钟前的监控数据 &quot;&quot;&quot; step = 20 now = int(time.time()) start = now - 300 end = now - 300 params = ( (&#x27;query&#x27;, str(query)), (&#x27;start&#x27;, str(start)), (&#x27;end&#x27;, str(end)), (&#x27;step&#x27;, str(step)), ) response = requests.get( &#x27;http://localhost:9090/api/v1/query_range&#x27;, params=params) if response: return response.json() else: return Nonedef json_node_exporter_cadvisor(): kube_node_status_condition = simple_query( query=&#x27;kube_node_status_condition&#123;status=&quot;true&quot;&#125;==1&#x27;) kube_node_labels = simple_query(query=&#x27;kube_node_labels&#x27;) kube_node_info = simple_query(query=&#x27;kube_node_info&#x27;) try: cluster_count_old = &#123;&#125; with open(&quot;/home/server/prometheus/groups/node-exporter/config_node_exporter.json&quot;) as f: config = json.loads(f.read()) for node in config: cluster = node[&quot;labels&quot;][&quot;cluster&quot;] if cluster not in cluster_count_old: cluster_count_old[cluster] = 1 else: cluster_count_old[cluster] += 1 except: cluster_count_old = &#123;&#125; try: nodes_ready = [i[&quot;metric&quot;][&quot;node&quot;] for i in kube_node_status_condition[&quot;data&quot;][&quot;result&quot;]] node_label_dict = &#123; i[&quot;metric&quot;][&quot;node&quot;]: &#123; &quot;cluster&quot;: i[&quot;metric&quot;][&quot;cluster&quot;], &quot;group&quot;: i[&quot;metric&quot;].get(&quot;label_group&quot;) &#125; for i in kube_node_labels[&quot;data&quot;][&quot;result&quot;] &#125; node_version_dict = &#123; i[&quot;metric&quot;][&quot;node&quot;]: str( i[&quot;metric&quot;][&quot;kubelet_version&quot;]).strip(&quot;v&quot;).split(&quot;.&quot;) for i in kube_node_info[&quot;data&quot;][&quot;result&quot;] &#125; config_node_exporter = [] config_cadvisor = [] config_cadvisor_standalone = [] cluster_count_new = &#123;&#125; for n in nodes_ready: targets_9100 = [str(n) + &quot;:9100&quot;] targets_4194 = [str(n) + &quot;:4194&quot;] version = node_version_dict[n] cluster = node_label_dict[n][&quot;cluster&quot;] if cluster not in cluster_count_new: cluster_count_new[cluster] = 1 else: cluster_count_new[cluster] += 1 item_node = &#123;&quot;labels&quot;: node_label_dict[n], &quot;targets&quot;: targets_9100&#125; item_cadvisor = &#123; &quot;labels&quot;: node_label_dict[n], &quot;targets&quot;: targets_4194&#125; config_node_exporter.append(item_node) if int(version[1]) == 1 and int(version[1]) &gt;= 14: config_cadvisor_standalone.append(item_cadvisor) else: config_cadvisor.append(item_cadvisor) cluster_config_change = &#123; cluster: cluster_count_new.get(cluster, 0) - cluster_count_old.get(cluster) for cluster in cluster_count_old &#125; change_min = min(list(cluster_config_change.values())) if change_min &gt;= -3: #node节点减少如果大于3个则不自动更新配置 with open(&quot;/home/server/prometheus/groups/node-exporter/config_node_exporter.json&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_node_exporter, indent=4)) with open(&quot;/home/server/prometheus/groups/cadvisor/config_cadvisor.json&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_cadvisor, indent=4)) with open(&quot;/home/server/prometheus/groups/cadvisor-standalone/config_cadvisor_standalone.json&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_cadvisor_standalone, indent=4)) else: with open(&quot;/home/server/prometheus/groups/node-exporter/config_node_exporter.json.new&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_node_exporter, indent=4)) with open(&quot;/home/server/prometheus/groups/cadvisor/config_cadvisor.json.new&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_cadvisor, indent=4)) with open(&quot;/home/server/prometheus/groups/cadvisor-standalone/config_cadvisor_standalone.json.new&quot;, &quot;w&quot;) as f: f.write(json.dumps(config_cadvisor_standalone, indent=4)) msg = &quot;prometheus配置中node数量变更为&#123;&#125;，请确认配置: &#123;&#125;&quot;.format(str(change_min), str(cluster_config_change)) send_alarm(msg) return cluster_config_change except Exception as e: print(e)if __name__ == &quot;__main__&quot;: res = json_node_exporter_cadvisor() print(res)","tags":["kubernetes","k8s","prometheus","monitoring"]},{"title":"Hello World","path":"/1970/01/01/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"},{"title":"MacOS使用笔记","path":"/notes/mac/index.html","content":"MacOS时间不同步问题解决1sudo sntp -sS time.apple.com"},{"title":"关于我","path":"/more/index.html","content":"所谓人生，皆为记忆；话自谁出？已然忘记。 淮安|成都|天津|北京|杭州|future 运维工程师@杭州 email: &#99;&#x68;&#97;&#x6e;&#103;&#101;&#x64;&#105;&#x66;&#102;&#x40;&#x6f;&#x75;&#x74;&#108;&#111;&#x6f;&#107;&#46;&#x63;&#111;&#x6d;"},{"title":"notes","path":"/notes/index.html","content":"好记性不如烂笔头 HTTPS 根证书：https://www.cnblogs.com/429512065qhq/p/12581941.html 双向认证：https://help.aliyun.com/zh/api-gateway/user-guide/mutual-tls-authentication#title-3j6-y2z-1od双向认证中，企业使用自签证书的原因是 client 端证书更新成本高，使用自签名证书可以将证书过期时间设置更长（例如 50 年），从而避免了频繁的客户端证书更新操作 SSL 和 TLS: https://aws.amazon.com/cn/compare/the-difference-between-ssl-and-tls/Taher Elgamal 领导了 SSL 的开发，并于 1995 年公开发布了 SSL 2.0。SSL 旨在确保万维网上的通信安全。在 SSL 经历多次迭代后，Tim Dierks 和 Christopher Allen 于 1999 年创建了 TLS 1.0，作为 SSL 3.0 的后继者。目前，所有 SSL 证书均已停用。TLS 证书是行业标准。但是，业界仍使用术语 SSL 来指代 TLS 证书。TLS 证书在 SSL 证书基础上进行了迭代，并随着时间的推移对其进行了改进。SSL 证书和 TLS 证书的最终功能没有改变。 TCP over TLSHTTPS is HTTP on top of TLS on top of TCP Linux常用命令查看文件描述符未释放的文件1lsof +L1 | sort -nk7 macOS使用笔记常见使用问题macOS时间不同步问题解决1sudo sntp -sS time.apple.com 触发角失效1defaults write com.apple.dock mcx-expose-disabled -bool FALSE; killall Dock macOS版本升级macOS有时会更新失败，可通过下载最新版本macOS的全量安装包来完成更新https://support.apple.com/zh-cn/macos/upgrade 更新后可能需要重新安装developer tools 1xcode-select --install 好用的软件homebrew安装1234567891011121314151617181920iterm2htopkarabiner-elements #键盘改键位neofetch #screenfetch的跨平台版本visual-studio-codemicrosoft-remote-desktopvlcfeishuclipyanacondapyenvmultipass #ubuntu虚拟机wiznoteworkflowyvmware-fusion-tech-previewracket --caskmd5sha1sumbartendermos #鼠标滚轮优化balenaetcher #iso刻录到u盘 App Store安装123456RunCat #状态栏负载监控Hidden Bar #状态栏图标隐藏 Xnip #截图Magnet #窗口手势MenuMate #顶栏菜单改为右键Keka #压缩 其他1Downie #在线视频下载 flash player360极速浏览器是目前macOS下唯一可用的支持flash的浏览器https://browser.360.cn/ee/mac/index.html Windows123CHKenPlayer #曾经最小的播放器foobar2000Ventory 搜索引擎Google搜索设置 将语言改为English，这样就可以通过搜索关键字来区分中英文互联网内容"},{"title":"常用脚本工具","path":"/wiki/sh/index.html","content":"工欲善其事必先利其器"}]